{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В клетках ниже - процесс обучения и запуска классификатора для существительных-субъектов\n",
    "\n",
    "классификация существительных конечной точки устроена аналогичным образом, отличаясь тренировочным сетом и количеством классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = []\n",
    "\n",
    "with open ('padat_nouns.txt', 'r', encoding = 'utf-8') as pf:\n",
    "    c = pf.read()\n",
    "    for ent in c.split('\\n'):\n",
    "        if int(ent.split('\\t')[1]) >= 5:\n",
    "            nouns.append(ent.split('\\t')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_to_vec = [n+'_NOUN' for n in nouns] #train nouns\n",
    "nouns_to_class = [n+'_NOUN' for n in dataframe['nouns']] #nouns to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = list(set(nouns_to_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = []\n",
    "ws = []\n",
    "\n",
    "for w in h:\n",
    "    try:\n",
    "        vec = wv_from_bin[w]\n",
    "        vecs.append(vec)\n",
    "        ws.append(w)\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=n_classes).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified = []\n",
    "\n",
    "for word in nouns_to_class:\n",
    "    if word == 'No subject':\n",
    "        classified.append(None)\n",
    "    else:\n",
    "        try:\n",
    "            vect = wv_from_bin[word].reshape(1, -1)\n",
    "            classified.append(kmeans.predict(vect)[0])\n",
    "        except KeyError:\n",
    "            classified.append('Not in word2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание векторов глагол+конечная точка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv_vec = []\n",
    "\n",
    "for go, ve in zip(goal_list, verb_list):\n",
    "    print(go, ve)\n",
    "    try:\n",
    "        g = wv_from_bin[go]\n",
    "    except TypeError:\n",
    "        g = 0\n",
    "    v = wv_from_bin[ve+'_VERB']\n",
    "    if type(g)!= np.array:\n",
    "        gv_vec.append(v)\n",
    "    else:\n",
    "        gv_vec.append(np.add(g, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение размеченной выборки на train и test для отладки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_pos = np.vstack(train_df.subj_pos.values)\n",
    "class_42 = np.vstack(train_df.subj_class_freq_42.values)\n",
    "gv = np.vstack(train_df.goalVerb_vec.values)\n",
    "gc = np.vstack(train_df.goal_class.values)\n",
    "\n",
    "\n",
    "X = np.hstack((subj_pos, class_42,gv, gc))\n",
    "y = train_df.frame.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [10, 50],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8, 9, 10],\n",
    "    'criterion' :['gini', 'entropy'],\n",
    "    'verbose':[1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtree_grid_search(X,y,nfolds):\n",
    "    #create a dictionary of all values we want to test\n",
    "    param_grid = { \n",
    "    'n_estimators': [30, 40, 50, 60, 70],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : np.arange(5, 15),\n",
    "    'criterion' :['gini', 'entropy'],\n",
    "    'verbose':[1]}\n",
    "    tree_model=RandomForestClassifier()\n",
    "    #use gridsearch to test all values\n",
    "    dtree_gscv = GridSearchCV(tree_model, param_grid, cv=nfolds)\n",
    "    #fit model to data\n",
    "    dtree_gscv.fit(X, y)\n",
    "    return dtree_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_grid_search(X, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(criterion='gini', max_depth=9, max_features='sqrt', verbose=1, n_estimators= 40, min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['f1', 'f2', 'f3', 'f4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(cm, range(4), range(4))\n",
    "\n",
    "sn.set(font_scale=1.0) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 20}) # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказания на всём корпусе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_pos = np.vstack(ALL_CORP.subj_pos.values)\n",
    "class_42 = np.vstack(ALL_CORP.subj_class_freq_42.values)\n",
    "gv = np.vstack(ALL_CORP.goalVerb_vec.values)\n",
    "gc = np.vstack(ALL_CORP.goal_class.values)\n",
    "\n",
    "\n",
    "ac = np.hstack((subj_pos, class_42, gc, gv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = rfc.predict(ac)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
